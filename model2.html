<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" rel="stylesheet">
    <title>Summer CAM WDD Using AI</title>
    <style>
        #div1 img {
            width: 600px;
            height: 300px;
        }
      main div[id^="div"] {
        border-bottom: 1px solid #000;
        padding-bottom: 10px;
        margin-bottom: 20px;
    }
    </style>

    <script src="data.js"></script>

</head>
<body>
    <main role="main" class="container">
        <div class="jumbotron mt-3" style="background-color: silver;"> 
            <h1 class="display-4 text-center">Summer CAM WDD Using AI</h1>
        </div>


        <div id="div1">
            <h2>Section 1. What is a convolutional neural network?</h2>
            <ul>
                <li>It tries to find an edge or pattern in an image</li>
                <li>It usually consists of one or more convolution plus pooling layer, and one fully connected (FC) layer</li>
                <li>When doing convolution on an image, we use a 5x5 filter. Further, we may apply several such filters to detect edge/pattern along several lines</li>
                <li>The cost function will be</li>
                <li>The last layer is output lay where we use a so-called Sigmoid activation, so that several outputs can be used.
                    <br>
                    <img src="convolutionExample3.jpg" alt="Convolution Example" style="max-width: 100%; height: auto;">
                </li>
            </ul>
        </div>

        <div id="div2">
            <h2>Section 2. Load TensorFlow for JavaScript libraries</h2>
            <p>We will use TensorFlow.js to train the model.</p>
            <p>Click the 'Run' button below to import two JavaScript libraries.</p>
            <button id="runButton">Run</button>
        </div>

        <div id="div3">
                <!-- Console output will be displayed here -->
            </div>   

        <div id="div4">
            <h2>Section 3. The dataset of images</h2>
            <p>We will use a dataset from Google, <a href="https://storage.googleapis.com/learnjs-data/model-builder/mnist_images.png">https://storage.googleapis.com/learnjs-data/model-builder/mnist_images.png</a>, and their labels, <a href="https://storage.googleapis.com/learnjs-data/model-builder/mnist_labels_uint8">https://storage.googleapis.com/learnjs-data/model-builder/mnist_labels_uint8</a>.</p>
            <p>The dataset is a big image file. It contains 65,000 images, each of size 28 x 28 x 1. The label file contains 65,000 labels. Each image uses 10 numbers to indicate which digit the image represents.</p>

        </div>


        <div id="div5">
            <h2>Section 4. The JavaScript module to process the dataset</h2>
            <p>We will use a JavaScript class from ‘./data.js’ to process the dataset.</p>
            <button id="loadDatasetButton" onclick="loadDataset()">Load the dataset</button>
        </div>

        <div id="div6">
             <!-- Lengths of trainImages and trainLabels will be displayed here -->
        </div>

        <div id="div7">
             <h2>Section 5 We will show 20 images from the dataset</h2>
            <!-- Button for showing the first 20 images will be added here -->
            <button onclick="showFirst20Images(mnistData)">Show the first 20 images</button>
            <div id="imageContainer"></div>
        </div>
        <div id="div8">
            <h2>Section 6. Define a CNN</h2>
            <p>Our CNN has input of shape 28 x 28 x 1.</p>
            <p>The first layer is a convolution + pooling. We will use 8 filters, each filter has kernel size=5 x 5 and stride =1. The activation function is ‘relu’. We use the max pooling of size 2 x 2 with stride=[2,2].</p>
            <p>The second layer is also a convolution + pooling. This time, we use 16 filters each of kernel size=5x5 and stride =1. The activation function is also ‘relu’. We use the max pooling of size 2 x 2 with stride=[2,2].</p>
            <p>The third layer is a fully connected layer with shape * x 1.</p>
            <p>The last layer is the output layer, with 10 outputs representing 10 digits. The activation function is now ‘softmax’.</p>
                <!-- Other content -->
    <button onclick="defineModel()">Define the model</button>
        </div>
        <div id="div9"></div>
        <div id="div10">
            <h2>Section 7. Train the model using 5000 images</h2>
            <p>The batch size = 512, and epochs = 10</p>
            <p>The test size = 1000</p>
            <p>The callbacks have name='Model Training', tab='Model', styles='{height: 1000px}', metrics={'loss', 'val_loss', 'acc', 'val_acc'}</p>
            <button onclick="trainModel()">Train the model</button>
        </div>
        <div id="div11"></div>
        <div id="div12">
            <h2>Section 8. Evaluate the model</h2>
            <p>We will obtain 500 images from the dataset mnistData.</p>
            <p>We use the trained model to calculate the predictions and then compare the predictions with the provided labels.</p>
            <p>We then draw a confusion matrix to show for each digit, how many images are labeled for that digit and how many images that predicted to that digit. Further, how many differences.</p>
            <button onclick="showConfusionMatrix(globalModel, mnistData)">Show a confusion matrix</button>
        </div>
        <div id="div13"></div>
 
    </main>

  <style>
    body {
    background-color: silver;
    margin: 0;
    padding: 0;
}

.banner {
    text-align: center;
    padding: 20px;
    background-color: #ffffff;
    box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2);
}

.banner h1 {
    margin: 0;
    color: #333333;
}



  </style>


    <script>

document.getElementById('runButton').addEventListener('click', function() {
            console.log("Loading TensorFlow.js libraries...");
            var tfScript = document.createElement('script');
            tfScript.src = "https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js";
            document.body.appendChild(tfScript);

            var tfVisScript = document.createElement('script');
            tfVisScript.src = "https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@1.0.2/dist/tfjs-vis.umd.min.js";
            document.body.appendChild(tfVisScript);

            tfScript.onload = function() {
                document.getElementById('div3').innerHTML += "TensorFlow.js library loaded successfully";
    //            console.log("TensorFlow.js library loaded successfully");
            }

            tfVisScript.onload = function() {
                document.getElementById('div3').innerHTML += "TensorFlow.js visualization  library loaded successfully";

      //          console.log("TensorFlow.js visualization library loaded successfully");
            }
        });

    let mnistData;
    async function loadDataset() {
      try {
        mnistData = new MnistData();
        await mnistData.load();
        displayDatasetShape(mnistData);


        //console.log('Dataset and labels loaded successfully');
      } catch (error) {
        console.error('Error loading dataset and labels:', error);
      }
    }
    function displayDatasetShape(data) {
      const images = data.trainImages;
      const labels = data.trainLabels;
      const imagesShape = images.length;
      const labelsShape = labels.length;
      document.getElementById('div6').innerText = `Images shape: ${imagesShape}, Labels shape: ${labelsShape}`; 
    }
   

/*
        document.getElementById('loadDatasetButton').addEventListener('click', function() {
            console.log("Processing the dataset...");
            // Assuming the data.js file contains a class for processing the dataset
            // Replace the below code with the actual implementation from data.js
            class DatasetProcessor {
                constructor() {
                    // Assume the dataset processing logic is implemented here
                    this.trainImages = [];
                    this.trainLabels = [];
                }
            }

            // Instantiate the DatasetProcessor and save it to a global variable
            window.mnistData = new DatasetProcessor();

            // Display the lengths of trainImages and trainLabels in div6
            document.getElementById('div6').innerText = "Length of trainImages: " + mnistData.trainImages.length + ", Length of trainLabels: " + mnistData.trainLabels.length;
        });

*/

async function showFirst20Images(mnistData) {
  
  const examples = mnistData.nextTestBatch(20); // Obtain 20 images from mnistData
  const surfaceElement = document.getElementById('div7'); // Get the surface element by its ID

  const images = examples.xs;
  for (let i = 0; i < 20; i++) {
    const imageTensor = images.slice([i, 0], [1, 784]).reshape([28,28,1]); // Extract the image tensor
    // const imageDataArray = imageTensor.reshape([28,28,1]); // Convert the tensor to a regular array

    const imageElement = document.createElement('canvas'); // Create a canvas element
    imageElement.width = 28;
    imageElement.height = 28;
    const ctx = imageElement.getContext('2d');
    const imageData = ctx.createImageData(28, 28); // Create an ImageData object

    await tf.browser.toPixels(imageTensor, imageElement);
    //for (let j = 0; j < imageDataArray.length; j++) {
    //  imageData.data[j] = imageDataArray[j]; // Set the pixel data for the image
    //}

    // ctx.putImageData(imageData, 0, 0); // Draw the image data onto the canvas

    surfaceElement.appendChild(imageElement); // Add the canvas element to the surface

    const label=examples.labels.slice([i,0], [1, 10]);
    const labelDiv = document.createElement('div');
    labelDiv.textContent = `Label: ${label}`;
    surfaceElement.appendChild(labelDiv);
  } 
}

let globalModel; // Global variable to store the model


function defineModel() {
    const model = tf.sequential();
    model.add(tf.layers.conv2d({
        inputShape: [28, 28, 1],
        filters: 8,
        kernelSize: 5,
        strides: 1,
        activation: 'relu',
        kernelInitializer: 'varianceScaling'
    }));
    model.add(tf.layers.maxPooling2d({
        poolSize: [2, 2],
        strides: [2, 2]
    }));
    model.add(tf.layers.conv2d({
        kernelSize: 5,
        filters: 16,
        strides: 1,
        activation: 'relu',
        kernelInitializer: 'varianceScaling'
    }));
    model.add(tf.layers.maxPooling2d({
        poolSize: [2, 2],
        strides: [2, 2]
    }));
    model.add(tf.layers.flatten());
    model.add(tf.layers.dense({
        units: 10,
        kernelInitializer: 'varianceScaling',
        activation: 'softmax'
    }));

    model.compile({
        optimizer: 'adam',
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
    });

    globalModel=model;
    tfvis.show.modelSummary(document.getElementById('div9'), model, document.getElementById('div9'));
}

function trainModel() {
    const batchSize = 512;
    const epochs = 10;
    const testSize = 1000;
    const metrics = ['loss', 'acc'];
    const callbacks = tfvis.show.fitCallbacks(
        document.getElementById('div11'),
        //{ name: 'Model Training', tab: 'Model', styles: { height: 400 } }, 
        metrics);

    globalModel.compile({
        optimizer: 'adam',
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
    });

    const [trainDataXs, trainDataLabels] = tf.tidy(() => {
        const d = mnistData.nextTrainBatch(5000);
        return [
            d.xs.reshape([5000, 28, 28, 1]),
            d.labels
        ];
    });

    const [testDataXs, testDataLabels] = tf.tidy(() => {
        const d = mnistData.nextTestBatch(testSize);
        return [
            d.xs.reshape([testSize, 28, 28, 1]),
            d.labels
        ];
    });

    globalModel.fit(trainDataXs, trainDataLabels, {
        batchSize,
        epochs,
        validationData: [testDataXs, testDataLabels],
        callbacks
    });
}


        const classNames = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine'];

        function doPrediction(model, data, testDataSize = 500) {
        const IMAGE_WIDTH = 28;
        const IMAGE_HEIGHT = 28;
        const testData = data.nextTestBatch(testDataSize);
        const testxs = testData.xs.reshape([testDataSize, IMAGE_WIDTH, IMAGE_HEIGHT, 1]);
        const labels = testData.labels.argMax(-1);
        const preds = model.predict(testxs).argMax(-1);

        testxs.dispose();
        return [preds, labels];
        }

        async function showConfusionMatrix(model, data) {
        const [preds, labels] = doPrediction(model, data);
        const confusionMatrix = await tfvis.metrics.confusionMatrix(labels, preds);
        //const container = {name: 'Confusion Matrix', tab: 'Evaluation'};
        const container = document.getElementById('div13');
        tfvis.render.confusionMatrix(container, {values: confusionMatrix, tickLabels: classNames});

        labels.dispose();
        }

    </script>

<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@1.16.1/dist/umd/popper.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"></script>
</script>
</body>
</html>